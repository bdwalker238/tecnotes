---
title: "Identifing IO performance problem with iostat. "
series: [Linux]
date: 2025-10-12
draft: false
weight: 10
tags: [Linux]
categories: [Linux, veritas]
ShowToc: false
---

 Quick article, what to look for when assessing iostat output due to slow performance on a  database ( DB2, MySQL, Postgres, Oracle  ) server. If you observed CPU run queue been blocked/high software interrupts. Here is a sample from  iostat   where I  diagnose wait IO root cause of a database hang , which was wait IO -

If you observe
-----

	$ iostat -kxy 10 1

	Linux 4.18.0-553.61.1.el8_10.x86_64 (hostname)     03/29/2023      _x86_64_        (32 CPU)   

	10/06/25  16:31:50
	avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           7.87    0.00    0.00    3.53    0.00    85.28

	Device	r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util

	etc
	sdd	1.32	3.11	21.93	  62.34	  0.0	   0.01	   0.4    0.47  4.46	78.46	0.25	16.62	20.04	4.75	2.211 
	etc
	
	sdl	1.31	3.11	21.93	  21.94	  0.0	   0.01	   0.3    0.47  4.46	78.09	0.25	16.62	20.04	4.75	2.211	
	etc

	$ cat  /sys/block/sdl/device/queue_depth
	64

	$  cat  /sys/block/sdd/device/queue_depth
	64

Figure 1

The w_await column in Figure 1 indicated San array, wasnâ€™ keeping with amount of IO operations issued by the database.  This can be  confirmed @  https://access.redhat.com/articles/524353 -

The avgqu-sz is the average number of io contained within both the io scheduler queue and storage lun queue. If the reported avgqu-sz in the sample is much less than the allowed lun queue_depth (and the sample time is small so averaging isn't hiding a much larger peak queue size), then there is little time spent within the scheduler queue. The scheduler will continue passing io to the driver while the number of io still outstanding to the driver (io currently being worked on by storage) remains under the lun's queue_depth limit. In such cases, then the await time is dominated by storage servicing time alone. Under these circumstances(low avgqu-sz), high await time is due to storage side issues.    
